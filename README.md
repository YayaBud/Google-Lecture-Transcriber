# ğŸ“ NoteFlow â€” AI-Powered Lecture Transcription & Study Assistant

**NoteFlow** is an AI-powered lecture transcription and note-generation platform designed to improve **accessibility and learning efficiency**, especially for **Deaf and Hard-of-Hearing (HoH) students**.

It captures live lecture audio, transcribes it in real time, extracts key concepts using AI, and converts raw speech into **structured, searchable study material**â€”all accessible through a modern web dashboard.

---

## ğŸš€ Why NoteFlow?

Traditional lectures rely heavily on audio, creating a significant accessibility gap. NoteFlow bridges this gap by ensuring that **understandingâ€”not just hearingâ€”is accessible to everyone**.

**Key value propositions:**
- Real-time visual access to lectures
- Reduced dependency on interpreters
- Persistent, searchable academic records
- Seamless integration with Googleâ€™s ecosystem

---

## ğŸ§  Core Capabilities

- ğŸ™ï¸ **Live Lecture Recording**  
  Capture audio directly from the browser with a single click.

- ğŸ“ **AI-Powered Transcription & Summarization**  
  - Speech-to-text using **OpenAI Whisper**  
  - Structured summaries and key points generated by **Google Gemini**

- ğŸ“‚ **Smart Organization**  
  Organize notes into folders, mark favorites, and revisit concepts instantly.

- ğŸ” **Searchable Transcripts**  
  Quickly find keywords, topics, or concepts across all lectures.

- â˜ï¸ **Google Docs Integration**  
  Export notes directly to Google Docs for long-term storage and sharing.

- ğŸ” **Secure Authentication**  
  Login using **Google OAuth**, ensuring a frictionless and secure experience.

---

## ğŸ—ï¸ Project Architecture

NoteFlow follows a clean **frontendâ€“backend separation**:

### Frontend (`/frontend`)
- **Tech Stack:** React, TypeScript, Vite, Tailwind CSS, Radix UI  
- Handles UI rendering, audio recording controls, dashboards, and note visualization.

### Backend (`/backend`)
- **Tech Stack:** Flask (Python), MongoDB  
- Responsibilities:
  - User authentication (Google OAuth)
  - Audio processing
  - AI model orchestration (Whisper + Gemini)
  - Data storage and retrieval
  - Google Docs API integration

---

## ğŸ”„ High-Level Workflow

1. User logs in via **Google OAuth**
2. Lecture audio is recorded from the browser
3. Audio is transcribed using **OpenAI Whisper**
4. Transcript is summarized and structured using **Google Gemini**
5. Notes are stored in MongoDB
6. User can export notes to **Google Docs** with one click

---

## ğŸ› ï¸ Technologies Used

### Frontend
- React
- TypeScript
- Tailwind CSS
- Radix UI
- Vite

### Backend
- Flask (Python)
- MongoDB
- PyMongo

### AI & Cloud
- **OpenAI Whisper** â€” Speech-to-Text
- **Google Gemini** â€” AI Summarization & Structuring
- **Google OAuth** â€” Authentication
- **Google Docs API** â€” Note export & persistence

---

## âš¡ Quick Start Guide

### 1ï¸âƒ£ Backend Setup

```bash
cd backend
# Follow instructions in backend/README.md
python app.py
